{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df99ea91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data is loading...\n",
      "Training data is being centered...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import cv2 \n",
    "\n",
    "DataDir=\"F:/2022_Summer/data\"\n",
    "Categories=[\"Post-Injury\", \"Pre-Injury\"]\n",
    "\n",
    "trainingdata=[] \n",
    "def createtrainingdata():\n",
    "#creates a data set of images and labels \n",
    "    print(\"Training data is loading...\")\n",
    "    premat=[]\n",
    "    postmat=[]\n",
    "    for category in Categories: \n",
    "        path=os.path.join(DataDir,category)\n",
    "        classnum=Categories.index(category)\n",
    "        for vid in os.listdir(path):\n",
    "            vpath=os.path.join(path,vid)\n",
    "            j=0\n",
    "            for frame in os.listdir(vpath): \n",
    "                img_array=cv2.imread(os.path.join(vpath,frame),0)\n",
    "                #if j==0: \n",
    "                    #vid_array=img_array\n",
    "                #else:\n",
    "                    #vid_array=np.concatenate([vid_array,img_array])\n",
    "                if classnum ==0:\n",
    "                    postmat.append(img_array)\n",
    "                else:\n",
    "                    premat.append(img_array)\n",
    "                #j=j+1\n",
    "                trainingdata.append([img_array,classnum])\n",
    "    \n",
    "    postav=np.average(np.array(postmat))\n",
    "    #print(postav)\n",
    "    preav=np.average(np.array(premat))\n",
    "    #print(preav)\n",
    " \n",
    "    \n",
    "    #Centers the data set to control for the lighting and improve processing speed \n",
    "    print(\"Training data is being centered...\")\n",
    "    for d in trainingdata: \n",
    "        if d[1]==1:\n",
    "            d[0]=d[0]-preav\n",
    "        else:\n",
    "            d[0]=d[0]-postav\n",
    "    \n",
    "                           \n",
    "    print(\"Done!\")\n",
    "createtrainingdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b374db1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is randomized!\n"
     ]
    }
   ],
   "source": [
    "#Randomizes the order of the data set \n",
    "import random \n",
    "random.shuffle(trainingdata)\n",
    "print(\"Data is randomized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbe2ac07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4160, 425, 425)\n",
      "(425, 425)\n",
      "Data is formatted!\n"
     ]
    }
   ],
   "source": [
    "#Changes the trainingdata into X and Y numpy arrays to be inputted into the model \n",
    "X=[]\n",
    "Y=[]\n",
    "for features,label in trainingdata:\n",
    "    X.append(features)\n",
    "    Y.append(label)\n",
    "X=np.array(X)\n",
    "Y=np.array(Y)\n",
    "print(X.shape)\n",
    "print(X[1].shape)\n",
    "X=X.reshape(-1,X[1].shape[0],X[1].shape[1],1)\n",
    "\n",
    "print(\"Data is formatted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd5c48dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is saved!\n"
     ]
    }
   ],
   "source": [
    "#saves training data \n",
    "import pickle \n",
    "pickle_out=open(\"X.pickle\", \"wb\")\n",
    "pickle.dump(X,pickle_out)\n",
    "pickle_out.close()\n",
    "pickle_out=open(\"Y.pickle\", \"wb\")\n",
    "pickle.dump(Y,pickle_out)\n",
    "pickle_out.close()\n",
    "print(\"Data is saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62f44c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "104/104 [==============================] - 11s 107ms/step - loss: 0.4493 - accuracy: 0.8053 - val_loss: 0.3704 - val_accuracy: 0.7993\n",
      "Epoch 2/8\n",
      "104/104 [==============================] - 11s 101ms/step - loss: 0.2634 - accuracy: 0.9005 - val_loss: 0.3516 - val_accuracy: 0.8558\n",
      "Epoch 3/8\n",
      "104/104 [==============================] - 10s 101ms/step - loss: 0.1589 - accuracy: 0.9453 - val_loss: 0.1174 - val_accuracy: 0.9700\n",
      "Epoch 4/8\n",
      "104/104 [==============================] - 10s 100ms/step - loss: 0.0974 - accuracy: 0.9715 - val_loss: 0.0987 - val_accuracy: 0.9808\n",
      "Epoch 5/8\n",
      "104/104 [==============================] - 10s 100ms/step - loss: 0.0465 - accuracy: 0.9895 - val_loss: 0.0703 - val_accuracy: 0.9904\n",
      "Epoch 6/8\n",
      "104/104 [==============================] - 10s 100ms/step - loss: 0.0893 - accuracy: 0.9781 - val_loss: 0.0605 - val_accuracy: 0.9856\n",
      "Epoch 7/8\n",
      "104/104 [==============================] - 10s 100ms/step - loss: 0.0271 - accuracy: 0.9943 - val_loss: 0.0248 - val_accuracy: 0.9928\n",
      "Epoch 8/8\n",
      "104/104 [==============================] - 10s 101ms/step - loss: 0.0145 - accuracy: 0.9973 - val_loss: 0.0210 - val_accuracy: 0.9916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x221bd624d60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf \n",
    "import pickle \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time \n",
    "\n",
    "\n",
    "    \n",
    "#NAME=\"Pre-vs-Post-Injury-CNN-{}\".format(int(time.time()))\n",
    "NAME=\"Middle(10%),5_Images{}_SGD_Optimizer\".format(int(time.time()))\n",
    "tensorboard=TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir='logs/{}'.format(NAME), histogram_freq=1, profile_batch = 0\n",
    ")\n",
    "X=pickle.load(open(\"X.pickle\", \"rb\"))\n",
    "Y=pickle.load(open(\"Y.pickle\", \"rb\"))\n",
    "#Normalizes the values \n",
    "X=X/255.0\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Conv2D(64, (3,3),input_shape=(425, 425, 1)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"SGD\", metrics=['accuracy'])\n",
    "\n",
    "model.fit(X,Y, batch_size=32,epochs=8,validation_split=0.2,callbacks=[tensorboard, tensorboard_callback])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7f214f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53d10e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
