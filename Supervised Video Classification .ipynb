{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df99ea91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data is loading...\n",
      "80.16980072784314\n",
      "80.84310740398791\n",
      "Training data is being centered...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import cv2 \n",
    "\n",
    "DataDir=\"F:/2022_Summer/data\"\n",
    "Categories=[\"Post-Injury\", \"Pre-Injury\"]\n",
    "\n",
    "trainingdata=[] \n",
    "def createtrainingdata():\n",
    "#creates a data set of images and labels \n",
    "    print(\"Training data is loading...\")\n",
    "    premat=[]\n",
    "    postmat=[]\n",
    "    for category in Categories: \n",
    "        path=os.path.join(DataDir,category)\n",
    "        classnum=Categories.index(category)\n",
    "        for vid in os.listdir(path):\n",
    "            vpath=os.path.join(path,vid)\n",
    "            vid_array=[]\n",
    "            for frame in os.listdir(vpath): \n",
    "                img_array=cv2.imread(os.path.join(vpath,frame),0)\n",
    "                \n",
    "                if classnum ==0:\n",
    "                    postmat.append(img_array)\n",
    "                else:\n",
    "                    premat.append(img_array)\n",
    "            trainingdata.append([vid_array,classnum])\n",
    "    \n",
    "    postav=np.average(np.array(postmat))\n",
    "    print(postav)\n",
    "    preav=np.average(np.array(premat))\n",
    "    print(preav)\n",
    "    \n",
    "    #Centers the data set to control for the lighting\n",
    "    print(\"Training data is being centered...\")\n",
    "    for d in trainingdata: \n",
    "        if d[1]==1:\n",
    "            d[0]=d[0]-preav\n",
    "        else:\n",
    "            d[0]=d[0]-postav\n",
    "                           \n",
    "    print(\"Done!\")\n",
    "createtrainingdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b374db1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is randomized!\n"
     ]
    }
   ],
   "source": [
    "#Randomizes the order of the data set \n",
    "import random \n",
    "random.shuffle(trainingdata)\n",
    "print(\"Data is randomized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbe2ac07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is formatted!\n"
     ]
    }
   ],
   "source": [
    "#Changes the trainingdata into X and Y numpy arrays to be inputted into the model \n",
    "X=[]\n",
    "Y=[]\n",
    "for features,label in trainingdata:\n",
    "    X.append(features)\n",
    "    Y.append(label)\n",
    "\n",
    "X=np.array(X)\n",
    "Y=np.array(Y)\n",
    "X=X.reshape(-1,X[1].shape[0],X[1].shape[1],1)\n",
    "\n",
    "print(\"Data is formatted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd5c48dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is saved!\n"
     ]
    }
   ],
   "source": [
    "#saves training data \n",
    "import pickle \n",
    "pickle_out=open(\"X.pickle\", \"wb\")\n",
    "pickle.dump(X,pickle_out)\n",
    "pickle_out.close()\n",
    "pickle_out=open(\"Y.pickle\", \"wb\")\n",
    "pickle.dump(Y,pickle_out)\n",
    "pickle_out.close()\n",
    "print(\"Data is saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62f44c5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 35>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Activation(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 35\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtensorboard\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\vidan\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\vidan\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf \n",
    "import pickle \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time \n",
    "\n",
    "NAME=\"Pre-vs-Post-Injury-CNN-{}\".format(int(time.time()))\n",
    "\n",
    "tensorboard=TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "\n",
    "X=pickle.load(open(\"X.pickle\", \"rb\"))\n",
    "Y=pickle.load(open(\"Y.pickle\", \"rb\"))\n",
    "#Normalizes the values \n",
    "X=X/255.0\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Conv2D(64, (3,3),input_shape=X.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "model.fit(X,Y, batch_size=32,epochs=3,validation_split=0.1,callbacks=[tensorboard])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7f214f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53d10e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
